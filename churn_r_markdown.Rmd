---
title: "Churn"
author: Eva Manuela Roncancio Ruiz, Mayerlis Lissett Moya Villafane, Guillermo Luigui
  Ubaldo Nieto Angarita.
date: "2024-11-07"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# **PREDICCIÓN DE LA PÉRDIDA DE CLIENTES DE TELECOMUNICACIONES**

***Eva Manuela Roncancio Ruiz, \ Mayerlis Lissett Moya Villafane
, \ Guillermo Luigui Ubaldo Nieto Angarita.***

## **1. Contexto.**

Este conjunto de datos consta de 100 variables y aproximadamente 100.000 registros. Se presentan distintas variables que explican los atributos propios del sector de las telecomunicaciones y diversos factores esenciales para atender las necesidades de sus clientes.

La variable objetivo es la **rotación** (churn), que explica si el cliente cambiará de proveedor o no.

El sector de las telecomunicaciones es un mercado muy competitivo en el cual las compañías de telefonía celular generan atractivas campañas de publicidad que den valor agregado al cliente para lograr su estadía a largo plazo. Asimismo, este servicio demanda un considerable cuidado con los factores intangibles que pueden ocasionar que un usuario busque realizar portabilidades numéricas o cancelaciones definitivas. Por tal motivo, las variables que se consideran en el modelo deben reflejar los aspectos más importantes que puedan ser un factor de decisión para el cliente.  

Por otra parte, la segmentación del mercado es importante para la retención y rotación. Si bien el precio es primordial y puede generar una rápida y masiva vinculación de usuarios, la calidad dada por las compañías durante la prestación del servicio es indispensable para evitar portabilidades numéricas prematuras. Por esta razón, se debe entender que algunas variables serán de mayor importancia para unos clientes que para otros.  

Así bien, con este modelo se pretende analizar y entender los factores decisivos para el cliente, a fin de predecir su comportamiento comercial y permitir a los lideres del negocio tomar decisiones enfocadas en las variables que le dan este valor agregado a su servicio y que impactan en la permanencia de su mercado objetivo. 

## **2. Objetivos.**

### ***2.1 Objetivo General***
Crear un modelo de Machine Learning para predecir los clientes que abandonarán los servicios de telecomunicaciones en función de las variables objeto de estudio seleccionadas en este proyecto.

### ***2.2 Objetivos Especificos***

1.   Presentar un EDA Univariado y Multivariado a profundidad.
2.   Hacer uso de pruebas de Algoritmos para la comparación del rendimiento.
3.   Optimizar el modelo con pruebas de Algoritmo mediante tecnicas de hiperparametro.
4.   Presentar el modelo más optimo para la predicción del churn en el sector de las telecomunicaciones junto con el analisis de aplicabilidad.


## **3. Variables Objeto.**

### ***3.1 Variable Dependiente***
Churn: Reporte de los casos de abandono (con evolución entre 31 a 60 días después de la fecha de observación)

### ***3.2 Variables Independientes***
Seleccioandas en la Limpieza y Transformación de los Datos

---

- Traducimos del Ingles al Español el nombre de las variables (columnas) registradas en la Base de Datos para facilitar el manejo de las mismas en el analisis exploratorio de los datos.

https://docs.google.com/spreadsheets/d/1LVOgqnhx6SAmZuKD8iO3UyXzyE4Q5ctcPZ7sIxF4muA/edit?usp=sharing[texto del vínculo](https://)

## **4. Cargue de los Datos (paquetes, librerías, data)**
A continuación, se presenta el código desarrollado para la recolección, cargue, preparación y exploración de los datos.


```{r eval=FALSE, include=FALSE}
packages <- c("readr", "readxl", "httr", "tidyverse", "lubridate", "mice", "caret", "corrplot", "e1071", "xgboost")

# Install only packages that are not installed
install_if_missing <- function(package) {
  if (!require(package, character.only = TRUE)) {
    install.packages(package)
  }
}

# Apply the function to each package
invisible(lapply(packages, install_if_missing))

```

```{r warning=FALSE, include=FALSE}
# Vinculamos las librerías con funciones y herramientas necesarias para el despliegue de la data.
library(ggplot2) #Permite crear gráficos personalizados.
library(dplyr) #Permite manipular y analizar datos de forma eficiente.
library(readr) #Permite leer datos de archivos de texto de forma rápida.
library(httr) #Permite interactuar con APIs (conectar con servicios wed).
library(tidyverse) #Permite trabajar de manera coherente y eficiente con datos tabulares.
library(lubridate) #Permite trabajar con fechas y horas en R.
library(corrplot) #Permite graficar las correlaciones de variables continuas.
library(xgboost)
library(caret)

```

```{r include=FALSE}
data <- read_csv("telecom_customer_churn.csv")
```
## **5. Análisis Preliminar de los Datos**

### **5.1. Inspeción de Datos Basicos**

```{r}
# Corroboramos la cantidad de filas (registros), columnas (varibles).
dim(data)
```
```{r}
# Visualizamos los primeros registros de la data.
head(data)
```

```{r}
# Visualizamos los ultimos registros de la data.
tail(data)
```

```{r}
# Obtenemos una especificación del tipo de variable y registro de cada columna.
str(data)
```

### **5.2. Resumen estadístico básico**

```{r include=FALSE}
# Analizamos el Resumen Estadístico Básico. (min, max, media, mediana)
summary(data)
```

## **6. Gestión de valores duplicados y faltantes**
### **6.1 Manejo de duplicaciones**

```{r}
# Revisamos el problema que aparece en el codigo, el cual esta relacionado con la lectura de las librerias.
attr(data, "problems")
```

```{r}
# Corroboramos donde está ubicadao el error. En este caso, encontrando un tibble vacío indicando una estructura adecuada de los datos.
problems(data)
```

```{r include=FALSE}
# Verificamos la duplicidad de la data. (variables)
data_duplicada <- duplicated(names(data))
print(data_duplicada)
```

```{r}
# Observamos si hay nombres de columnas duplicadas.
duplicate_names <- names(data)[data_duplicada]
print(duplicate_names)
```

```{r include=FALSE}
# Identificamos valores faltantes (NA) en nuestro Data Frame "data"
valores_faltantes <- is.na(data)
print(valores_faltantes)
```
```{r}
# Identificamos el total de valores faltantes en la Data.
total_valores_faltantes <- sum(is.na(data))
print(total_valores_faltantes)
```



```{r include=FALSE}
# Identificamos los dominios de cada columna.
colnames(data)
```
### **6.2 Gestión de valores faltantes**

```{r}
data$rev_Mean <- ifelse(is.na(data$rev_Mean),
                                    mean(data$rev_Mean, na.rm = TRUE),
                                    data$rev_Mean)

data$rev_Mean <- ifelse(is.na(data$rev_Mean),
                                    mean(data$rev_Mean, na.rm = TRUE),
                                    data$rev_Mean)

data$totmrc_Mean <- ifelse(is.na(data$totmrc_Mean),
                                    mean(data$totmrc_Mean, na.rm = TRUE),
                                    data$totmrc_Mean)

data$da_Mean <- ifelse(is.na(data$da_Mean),
                                    mean(data$da_Mean, na.rm = TRUE),
                                    data$da_Mean)

data$ovrmou_Mean <- ifelse(is.na(data$ovrmou_Mean),
                                    mean(data$ovrmou_Mean, na.rm = TRUE),
                                    data$ovrmou_Mean)

data$ovrrev_Mean <- ifelse(is.na(data$ovrrev_Mean),
                                    mean(data$ovrrev_Mean, na.rm = TRUE),
                                    data$ovrrev_Mean)

data$vceovr_Mean <- ifelse(is.na(data$vceovr_Mean),
                                    mean(data$vceovr_Mean, na.rm = TRUE),
                                    data$vceovr_Mean)

data$datovr_Mean  <- ifelse(is.na(data$datovr_Mean),
                                    mean(data$datovr_Mean, na.rm = TRUE),
                                    data$datovr_Mean)

data$datovr_Mean  <- ifelse(is.na(data$datovr_Mean),
                                    mean(data$datovr_Mean, na.rm = TRUE),
                                    data$datovr_Mean)

data$roam_Mean <- ifelse(is.na(data$roam_Mean),
                                    mean(data$roam_Mean, na.rm = TRUE),
                                    data$roam_Mean)

data$change_mou <- ifelse(is.na(data$change_mou),
                                    mean(data$change_mou, na.rm = TRUE),
                                    data$change_mou)

data$change_rev <- ifelse(is.na(data$change_rev),
                                    mean(data$change_rev, na.rm = TRUE),
                                    data$change_rev)

data$avg6mou <- ifelse(is.na(data$avg6mou),
                                    mean(data$avg6mou, na.rm = TRUE),
                                    data$avg6mou)

data$avg6qty <- ifelse(is.na(data$avg6qty),
                                    mean(data$avg6qty, na.rm = TRUE),
                                    data$avg6qty)

data$avg6rev <- ifelse(is.na(data$avg6rev),
                                    mean(data$avg6rev, na.rm = TRUE),
                                    data$avg6rev)

data$hnd_price <- ifelse(is.na(data$hnd_price),
                                    mean(data$hnd_price, na.rm = TRUE),
                                    data$hnd_price)

data$phones <- ifelse(is.na(data$phones),
                                    mean(data$phones, na.rm = TRUE),
                                    data$phones)

data$models <- ifelse(is.na(data$models),
                                    mean(data$models, na.rm = TRUE),
                                    data$models)

data$rv <- ifelse(is.na(data$rv),mean(data$rv, na.rm = TRUE),data$rv)

data$lor <- ifelse(is.na(data$lor),
                                    mean(data$lor, na.rm = TRUE),
                                    data$lor)

Mode <- function(x) {
  ux <- unique(na.omit(x))
  ux[which.max(tabulate(match(x, ux)))]
}


data$income[is.na(data$income)] <- Mode(data$income)

data$truck <- ifelse(is.na(data$truck),
                                    mean(data$truck, na.rm = TRUE),
                                    data$truck)

data$numbcars <- ifelse(is.na(data$numbcars),
                                    mean(data$numbcars, na.rm = TRUE),
                                    data$numbcars)

data$forgntvl <- ifelse(is.na(data$forgntvl),
                                    mean(data$forgntvl, na.rm = TRUE),
                                    data$forgntvl)

data$area[is.na(data$area)] <- Mode(data$area)

data$eqpdays <- ifelse(is.na(data$eqpdays),
                                    mean(data$eqpdays, na.rm = TRUE),
                                    data$eqpdays)

data$ethnic[is.na(data$ethnic)] <- Mode(data$ethnic)

data$marital[is.na(data$marital)] <- Mode(data$marital)

# Impute missing values in the 'income' column using the Mode
data$adults[is.na(data$adults)] <- Mode(data$adults)

data$kid0_2 <- Mode(data$kid0_2)

data$kid3_5 <- Mode(data$kid3_5)

data$kid6_10 <- Mode(data$kid6_10)

data$kid11_15 <- Mode(data$kid11_15)

data$kid16_17 <- Mode(data$kid16_17)

data$creditcd <- Mode(data$creditcd)

data$hnd_webcap <- Mode(data$hnd_webcap)

data$ownrent <- Mode(data$ownrent)

data$dwlltype <- Mode(data$dwlltype)

data$dwllsize <- Mode(data$dwllsize)

data$infobase <- Mode(data$infobase)

data$prizm_social_one <- Mode(data$prizm_social_one)

data$dualband <- Mode(data$dualband)

data$refurb_new <- Mode(data$refurb_new)

data$mou_Mean <- ifelse(is.na(data$mou_Mean),
                                    mean(data$mou_Mean, na.rm = TRUE),
                                    data$mou_Mean)

data$HHstatin <- Mode(data$HHstatin)
```


### **6.3 Remover variables con valores unicos**

```{r}
# Remove the 'Customer_ID' column from the dataset
data <- data[, !names(data) %in% "Customer_ID"]
```

```{r}
data <- data[, !names(data) %in% "creditcd"]
data <- data[, !names(data) %in% "prizm_social_one"]
data <- data[, !names(data) %in% "dualband"]
data <- data[, !names(data) %in% "refurb_new"]
data <- data[, !names(data) %in% "hnd_webcap"]
data <- data[, !names(data) %in% "ownrent"]
data <- data[, !names(data) %in% "dwlltype"]
data <- data[, !names(data) %in% "infobase"]
data <- data[, !names(data) %in% "HHstatin"]
data <- data[, !names(data) %in% "dwllsize"]
data <- data[, !names(data) %in% "kid0_2"]
data <- data[, !names(data) %in% "kid3_5"]
data <- data[, !names(data) %in% "kid6_10"]
data <- data[, !names(data) %in% "kid11_15"]
data <- data[, !names(data) %in% "kid16_17"]
```


```{r eval=FALSE, include=FALSE}
library(caret)

# Define X and y
X <- data[, -which(names(data) == "churn")]  # Remove target variable 'churn'
y <- data$churn  # Target variable

# Perform feature selection using ANOVA (F-test)
# Use decision tree model 'rpart' for classification, which works well for categorical outcomes
control <- trainControl(method="cv", number=10)  # 10-fold cross-validation

# Apply feature selection using rpart (decision tree)
selector <- train(x = X, y = y, method = "rpart", 
                  trControl = control, 
                  preProcess = "scale")

# Get feature importance from the model
importance <- varImp(selector, scale = FALSE)

# Check if the importance has been calculated properly
if (!is.null(importance$importance)) {
  # Sort features by importance score and keep the feature names
  top_features_sorted <- importance$importance[, 1]
  
  # Create a data frame with feature names and importance scores
  top_features <- data.frame(Feature = rownames(importance$importance), Importance = top_features_sorted)
  
  # Sort the features by importance (decreasing)
  top_features_sorted <- top_features[order(top_features$Importance, decreasing = TRUE), ]
  
  # Display the top 20 features with names and scores
  print("Las 20 mejores características ordenadas por influencia:")
  print(head(top_features_sorted, 20))  # Show the top 20 features
} else {
  print("No importance data found. Please check the model.")
}


```



## **7. Analisis Exploratorio Univariado y Multivariado**
### **7.1 Análisis Univariado**
```{r}
# Analizamos la variable "new_cell". La variable contiene 3 niveles (categorias). Un factor se puede leer como una variable categórica en R.
data$new_cell <- as.factor(data$new_cell)
# Identificamos los niveles e la variable "data$new_cell". (categorias).
levels(data$new_cell)
```

Análisis: (Indica si el cliente es un nuevo usuario de telefonía móvil.) Se puede observar que: contiene 3 niveles (categorias).

```{r}
data$crclscod  <- as.factor(data$crclscod)
levels(data$crclscod)
```


Análisis: (Indica la clasificación "codigo" de crédito del cliente) Se puede observar que tiene 54 niveles (categorías).

```{r}
# Analizamos la variable "area".La variable es leída como un factor que tiene 19 niveles (categorías).
data$area   <- as.factor(data$area)
levels(data$area)
```

Analizamos la variable "area".La variable es leída como un factor que tiene 19 niveles (categorías).


```{r}
# Analizamos la variable "ethnic"
data$ethnic    <- as.factor(data$ethnic)
levels(data$ethnic)
```

Análisis:(Indica el código que representa el grupo étnico al que pertenece el cliente.) Se puede observar que tiene 17 niveles (categorías).

#### **7.1.1 VARIABLES CUANTITATIVAS**
```{r include=FALSE}
# Analizamos la variable "adults"
data$adults   <- as.factor(data$adults)
print(data$adults)
```

#### **7.1.2 TABLAS DE FRECUENCIA Y AGRUPACIÓN DE VARIABLES**
```{r}
# AGRUPACIONES
resultado_churn <- data %>%
  group_by(churn) %>%
  summarize(
    avg_monthly_charges = mean(rev_Mean, na.rm = TRUE),  # Ingreso mensual promedio
    avg_avgqty = mean(avgqty, na.rm = TRUE),                  # Promedio mensual de llamadas realizadas
    count = n()                                                # Contar el número de registros en cada grupo
  )

# Identificamos cuantas personas rotaron de servicio
print(resultado_churn)
```

Los clientes que no abandonaron el servicio (0 = No) tienen un ingreso mensual promedio de 59.2 y un promedio mensual de 178 llamadas al mes.
Los clientes que sí abandonaron el servicio (1 = Yes) tienen un ingreso mensual promedio de 58.2 y un promedio mensual de llamadas de 170 llamadas al mes.


#### **7.1.3 Gráfico de barras  del churn**
```{r}
# Visualización: Diagrama de barras para CHURN
ggplot(data, aes(x = as.factor(churn), fill = as.factor(churn))) +
  geom_bar(position = "dodge") +
  labs(title = "Distribucion del Churn",
       x = "Churn (0 = No, 1 = Si)",
       y = "Frecuencia",
       fill = "Churn") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_fill_brewer(palette = "Set2")
```


#### **7.1.4 Grafica de torta del Churn**
```{r}
data_summary <- data %>%
  count(churn) %>%
  mutate(percentage = n / sum(n) * 100)

ggplot(data_summary, aes(x = "", y = n, fill = as.factor(churn))) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar("y") +
  geom_text(aes(label = paste0(round(percentage, 1), "%")),
            position = position_stack(vjust = 0.5)) +
  labs(
    title = "Grafica de torta del Churn",
    x = NULL,  # Remove x-axis label
    y = NULL,  # Remove y-axis label
    fill = "Churn"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.text = element_blank(),  # Remove axis text
    axis.ticks = element_blank(),  # Remove axis ticks
    panel.grid = element_blank()  # Remove grid lines
  ) +
  scale_fill_brewer(palette = "Set2")

```

Dado el contexto de competencia en el sector de telecomunicaciones y la importancia de retener a los clientes, la tasa de abandono del 49.56% de los 100,000 clientes (49,562 usuarios) es un indicador crucial que refleja áreas de mejora en la satisfacción y fidelización del cliente. Este índice de churn sugiere que casi la mitad de los clientes encuentra suficiente motivación para cambiar de proveedor o cancelar el servicio, lo que representa una considerable pérdida de ingresos y una señal de posibles deficiencias en la percepción de valor agregado.


#### **7.1.5 Gráfico de barras de usuarios por nuevo usuarios**
```{r}
ggplot(data, aes(x = new_cell, fill = new_cell)) +
  geom_bar() +
  geom_text(stat = "count", aes(label = ..count..), vjust = -0.5) +  # Add count labels
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(
    title = "Distribucion de usuarios por nuevo usuario",
    x = "Nuevo usuario",
    y = "Cantidad de usuarios",
    fill = "Nuevo usuario"
  ) +
  scale_fill_brewer(palette = "Set2")
```


En este diagrama de Barras podemos observar 3 niveles (categorías) que corresponden a N, U y Y. Podemos observar que la frecuencia más alta radica en usuarios demarcados en el grupo U, con más de 50.000 usuarios registrados. Y el grupo con menores usuarios registrados es el N con menos de 20000 registros. El comportamiento de cambio de número entre los usuarios proporciona información importante sobre el manejo de datos, la experiencia del cliente y las razones potenciales de abandono en el contexto de telecomunicaciones.


#### **7.1.6 Distribución de usuarios por nuevo usuarios**
```{r}
data_summary <- data %>%
  count(new_cell) %>%
  mutate(percentage = n / sum(n) * 100,
         label = paste0(round(percentage, 1), "%"))

ggplot(data_summary, aes(x = "", y = n, fill = new_cell)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar("y") +
  labs(
    title = "Distribucion de usuarios por nuevo usuarios",
    x = NULL,  # Remove x-axis label
    y = NULL,  # Remove y-axis label
    fill = "Nuevo usuario"
  ) +
  geom_text(aes(label = label), position = position_stack(vjust = 0.5)) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.text = element_blank(),  # Remove axis text
    axis.ticks = element_blank(),  # Remove axis ticks
    panel.grid = element_blank()  # Remove grid lines
  ) +
  scale_fill_brewer(palette = "Set2")
```


Este gráfico de torta representa tres niveles de la variable "nuevo usuario", que refleja qué tan reciente es su incorporación a la telefonía móvil: **N**, **U**, y **Y**. El grupo **U** concentra la mayoría de los usuarios, con una distribución del **66.9%**, seguido por el grupo **Y**, que representa el **19.3%**, y finalmente el grupo **N**, que constituye el **13.8%**, siendo el más pequeño. Este análisis permite comprender la antigüedad de los usuarios en el servicio y su distribución por niveles.


#### **7.1.7  Distribución del promedio de llamadas de voz fallidas**
```{r}
ggplot(data, aes(x = drop_vce_Mean)) +
  geom_histogram(binwidth = 5, fill = "lightblue", color = "black") +
  labs(title = "Distribucion del promedio de llamadas de voz fallidas",
       x = "Llamadas de voz fallidas",
       y = "Frecuencia") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_fill_brewer(palette = "Set2")
```


El sesgo a la derecha en el diagrama de barras, que muestra una concentración de datos en valores bajos de fallas en llamadas, es una señal positiva sobre la calidad del servicio de telecomunicaciones, ya que indica que la mayoría de los usuarios experimenta pocas o ninguna llamada fallida. La concentración de datos en valores bajos sugiere que la red es confiable, y que la infraestructura técnica está funcionando bien para la mayoría de los usuarios. Esto ayuda a mejorar la percepción de calidad y reduce la probabilidad de abandono, ya que la experiencia de llamada es consistente.


#### **7.1.8  Distribución de la cantidad de minutos usados**
```{r}
ggplot(data, aes(x = totmou)) +
  geom_histogram(binwidth = 1000, fill = "lightblue", color = "black") +
  labs(title = "Distribucion de la cantidad de minutos usados",
       x = "Cantidad de minutos usados",
       y = "Frecuencia") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_fill_brewer(palette = "Set2")
```

Este diagrama de barras muestra el tiempo total en minutos que un cliente ha utilizado el servicio en relación con la cantidad de llamadas gestionadas. La gráfica revela un sesgo negativo hacia la derecha, lo que indica que la mayor parte de los datos se concentra en los valores más bajos a la izquierda. La mayoría de los clientes realiza llamadas de corta duración, lo cual podría indicar que los usuarios tienden a preferir comunicaciones rápidas, tal vez para tareas específicas y consultas breves. Esto puede sugerir que el servicio es utilizado principalmente para interacciones puntuales, en lugar de largas conversaciones.


#### **7.1.9 Distribución de la Cantidad de Total de Llamadas**
```{r}
ggplot(data, aes(x = totcalls)) +
  geom_histogram(binwidth = 1000, fill = "lightblue", color = "black") +
  labs(title = "Distribucion de la Cantidad de Total de Llamadas",
       x = "Cantidad de Total de Llamadas",
       y = "Frecuencia") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_fill_brewer(palette = "Set2")
```


Este diagrama de barras muestra la cantidad total de llamadas realizadas por el cliente durante toda su relación con la compañía. La distribución negativa hacia la derecha en este diagrama, con la mayoría de los clientes realizando menos de 25,000 llamadas, junto con la presencia de valores atípicos que llegan hasta las 75,000 llamadas o más sugiere que la mayoría de los clientes tiene un uso moderado del servicio. Esto es típico de una base de clientes compuesta principalmente por usuarios promedio o de bajo consumo, lo que puede ser característico de clientes residenciales o de aquellos que prefieren otros medios de comunicación.


#### **7.1.10 Grafica de barras de la etnicidad**

```{r}
ggplot(data, aes(x=as.factor(ethnic), fill=as.factor(ethnic) )) +
  geom_bar( ) +
  labs(title = "Grafica de barras de la etnicidad", x = "Etnicidad", y = "Cantidad", fill = "Etnicidad") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))
```

Se observa que los tres grupos étnicos más frecuentes son el grupo N, seguido por el grupo H y, en tercer lugar, el grupo S. 
La distribución de estos tres grupos étnicos principales (N, H y S) en el análisis de clientes puede tener varias implicaciones para la compañía, especialmente en la personalización de servicios y en las estrategias de marketing y retención. La identificación de los grupos étnicos más frecuentes permite personalizar servicios y ofertas que puedan resonar mejor con cada grupo. Esto puede incluir campañas de marketing culturalmente relevantes, la incorporación de beneficios específicos que respondan a preferencias o necesidades particulares, o la adaptación de la atención al cliente para reflejar prácticas y valores de cada grupo.


#### **7.1.11 Distribución de Número de Adultos**

```{r}
# Calculate the counts and percentages
data_summary <- data %>%
  count(adults) %>%
  mutate(percentage = n / sum(n) * 100)

# Create the pie chart
ggplot(data_summary, aes(x = "", y = n, fill = as.factor(adults))) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar("y") +
  geom_text(aes(label = paste0(round(percentage, 1), "%")),
            position = position_stack(vjust = 0.5)) +
  labs(title = "Distribucion de Numero de Adultos",
       x = NULL,
       y = NULL,
       fill = "Numero de Adultos") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.text = element_blank(),  # Remove axis text
    axis.ticks = element_blank(),  # Remove axis ticks
    panel.grid = element_blank()  # Remove grid lines
  ) +
  scale_fill_brewer(palette = "Set2")
```


La variable "número de adultos" representa la cantidad de personas adultas que viven en el hogar del cliente. Este gráfico muestra la distribución porcentual de esta variable, donde los hogares con **dos adultos** son mayoría con un **46.1%**, seguidos por los hogares con **un adulto** con un **22.3%**, luego **tres adultos** con un **13.7%**, **cuatro adultos** con un **8.8%**, **cinco adultos** con un **4.8%** y, finalmente, **seis adultos** con un **4.3%**. Este análisis es útil para comprender las características de los clientes y evaluar si el número de adultos en el hogar influye en el comportamiento del cliente, como mayores gastos o una mayor necesidad de servicios de telecomunicaciones, lo que podría impactar en la rotación (churn).


#### **7.1.12 Distribución del total de meses en el servicio**

```{r}
ggplot(data, aes(x = months)) +
  geom_histogram(binwidth = 5, fill = "lightblue", color = "black") +
  labs(
    title = "Distribucion del total de meses en el servicio",
    x = "Numero total de meses en el servicio",
    y = "Frecuencia"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_x_continuous(breaks = seq(0, max(data$months, na.rm = TRUE), by = 5)) +  # Set x-axis breaks
  scale_y_continuous(breaks = seq(0, max(table(cut(data$months, seq(0, max(data$months, na.rm = TRUE), by = 5)))), by = 2000))
```


Este diagrama muestra un sesgo positivo, con la mayoría de la distribución concentrada entre los **5 y 25 meses**. Esto sugiere que hay una menor cantidad de clientes después de los **25 meses**, lo que indica una tendencia a la disminución de clientes conforme aumenta el tiempo.


#### **7.1.13 Distribución del número de días que el cliente ha tenido su equipo actual.**

```{r}
ggplot(data, aes(x = eqpdays)) +
  geom_histogram(binwidth = 100, fill = "lightblue", color = "black") +
  labs(
    title = "Distribucion del numero de dias que el cliente ha tenido su equipo actual.",
    x = "Numero de dias que el cliente ha tenido su equipo actual.",
    y = "Frecuencia"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_x_continuous(breaks = seq(0, max(data$eqpdays, na.rm = TRUE), by = 100)) +  # Set x-axis breaks
  scale_y_continuous(breaks = seq(0, max(table(cut(data$eqpdays, seq(0, max(data$eqpdays, na.rm = TRUE), by = 100)))), by = 2000))  # Set y-axis breaks
```


Esta distribución presenta un sesgo positivo, con la mayoría de los usuarios concentrados entre **100 y 500 días** desde que adquirieron su equipo actual. Esto indica que, después de los **300 días**, hay una menor cantidad de usuarios con equipos más antiguos, lo cual podría influir en la rotación de clientes (churn), ya que los equipos más viejos pueden estar relacionados con una mayor propensión a quedarse insatisfechos con el servicio.


#### **7.1.14 Distribución del precio del telefono.**

```{r}
ggplot(data, aes(x = hnd_price)) +
  geom_histogram(binwidth = 20, fill = "lightblue", color = "black") +
  labs(
    title = "Distribucion del precio del telefono.",
    x = "Precio del telefono",
    y = "Frecuencia"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_x_continuous(breaks = seq(0, max(data$hnd_price, na.rm = TRUE), by = 40)) +  # Set x-axis breaks
  scale_y_continuous(breaks = seq(0, max(table(cut(data$hnd_price, seq(0, max(data$hnd_price, na.rm = TRUE), by = 20)))), by = 2000))  # Set y-axis breaks

```

Se observa que los precios de los teléfonos varían entre **0** y **160**, y que hay menos usuarios con teléfonos cuyo precio excede los **160**.


#### **7.1.15 Distribución de minutos de uso mensual promedio.**

```{r}
ggplot(data, aes(x = mou_Mean)) +
  geom_histogram(binwidth = 200, fill = "lightblue", color = "black") +
  labs(
    title = "Distribucion de minutos de uso mensual promedio.",
    x = "Minutos de uso mensual promedio.",
    y = "Frecuencia"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_x_continuous(breaks = seq(0, max(data$mou_Mean, na.rm = TRUE), by = 1000)) +  # Set x-axis breaks
  scale_y_continuous(breaks = seq(0, max(table(cut(data$mou_Mean, seq(0, max(data$mou_Mean, na.rm = TRUE), by = 200)))), by = 2000))  # Set y-axis breaks
```


Esta distribución muestra un sesgo positivo, con la mayoría de los usuarios concentrados en un rango de **0 a 1000 minutos** promedio por mes. Esto sugiere que la mayoría de los usuarios gastan una cantidad moderada de minutos al mes, lo que refleja su comportamiento típico de uso del servicio.


#### **7.1.16 Distribución del cargo recurrente mensual total promedio.**

```{r}
ggplot(data, aes(x = totmrc_Mean)) +
  geom_histogram(binwidth = 10, fill = "lightblue", color = "black") +
  labs(
    title = "Distribucion del cargo recurrente mensual total promedio.",
    x = "Cargo recurrente mensual total promedio",
    y = "Frecuencia"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_x_continuous(breaks = seq(0, max(data$totmrc_Mean, na.rm = TRUE), by = 20)) +  # Set x-axis breaks
  scale_y_continuous(breaks = seq(0, max(table(cut(data$totmrc_Mean, seq(0, max(data$totmrc_Mean, na.rm = TRUE), by = 10)))), by = 2000))  # Set y-axis breaks
```


La distribución presenta un sesgo positivo, con el cargo recurrente mensual promedio concentrado entre **20** y **80**. Esto indica que la mayoría de los usuarios tienen un cargo mensual dentro de este rango.


#### **7.1.17 Distribución del numero de telefonos.**

```{r}
ggplot(data, aes(x = phones)) +
  geom_histogram(binwidth = 1, fill = "lightblue", color = "black") +
  labs(
    title = "Distribucion del numero de telefonos.",
    x = "Numero de telefonos",
    y = "Frecuencia"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_x_continuous(breaks = seq(0, max(data$phones, na.rm = TRUE), by = 1)) +  # Set x-axis breaks
  scale_y_continuous(breaks = seq(0, max(table(cut(data$phones, seq(0, max(data$phones, na.rm = TRUE), by = 1)))), by = 5000))  # Set y-axis breaks

```


La distribución muestra un sesgo positivo, con una concentración entre **1** y **2 teléfonos**, siendo el **1 teléfono** el caso más común. Es menos frecuente que los usuarios tengan más de **2 teléfonos**.


## **8. Análisis Bivariado**
### **8.1 Frecuencia de Adultos por Churn**
```{r}
ggplot(data, aes(x = as.factor(churn), fill = as.factor(adults))) +
  geom_bar(position = "dodge") +
  theme_minimal() +
  labs(title = "Frecuencia de Adultos por Churn", x = "Churn (0 = No, 1 = Si)", y = "Cantidad", fill = "Número de Adultos") +
  scale_fill_brewer(palette = "Set2")
```

La ausencia de una influencia visible del número de adultos en el churn indica que esta variable podría no ser un factor determinante en la decisión de los clientes de permanecer o abandonar el servicio. Esto sugiere que el número de adultos en el hogar puede tener una relación muy débil, o incluso inexistente, con la fidelidad o satisfacción de los clientes en este contexto de telecomunicaciones.


### **8.2 Frecuencia de Ingreso por Churn**
```{r}
ggplot(data, aes(x = as.factor(churn), fill = as.factor(income))) +
  geom_bar(position = "dodge") +
  theme_minimal() +
  labs(title = "Frecuencia de Ingreso por Churn", x = "Churn (0 = No, 1 = Sí)", y = "Cantidad", fill = "Ingreso")
```

La falta de influencia del ingreso en el churn indica que es posible priorizar otras variables en las estrategias de retención y en la construcción del modelo predictivo. Esto optimiza el análisis, focalizando en factores que realmente afectan la lealtad y satisfacción de los clientes.


### **8.3 Frecuencia de Área por Churn**
```{r}
ggplot(data, aes(x = as.factor(churn), fill = area)) +
  geom_bar(position = "dodge") +
  theme_minimal() +
  labs(title = "Frecuencia de Área por Churn", x = "Churn (0 = No, 1 = Sí)", y = "Cantidad", fill = "Área") 
```
No se observa ninguna influencia de las áreas geográficas  en el churn.

### **8.4 Frecuencia de Etnicidad por Churn**
```{r}
ggplot(data, aes(x = as.factor(churn), fill = ethnic)) +
  geom_bar(position = "dodge") +
  theme_minimal() +
  labs(title = "Frecuencia de Etnicidad por Churn", x = "Churn (0 = No, 1 = Sí)", y = "Cantidad", fill = "Etnicidad") 
```
No observamos una relación clara entre los grupos étnicos y en el churn.

### **8.5 Frecuencia de Estado Civil por Churn**
```{r}
ggplot(data, aes(x = as.factor(churn), fill = marital)) +
  geom_bar(position = "dodge") +
  theme_minimal() +
  labs(title = "Frecuencia de Estado Civil por Churn", x = "Churn (0 = No, 1 = Sí)", y = "Cantidad", fill = "Estado Civil") +
  scale_fill_brewer(palette = "Set2")
```

Al comparar el estado civil de los clientes, no se observa una diferencia significativa en el churn.

### **8.6 Caja de bigotes de Promedio de llamadas no contestadas por Churn**

```{r}
# Calculate the IQR and define the outlier bounds
Q1 <- quantile(data$unan_vce_Mean, 0.25, na.rm = TRUE)
Q3 <- quantile(data$unan_vce_Mean, 0.75, na.rm = TRUE)
IQR_value <- Q3 - Q1

# Define the lower and upper bounds for outliers
lower_bound <- Q1 - 1.5 * IQR_value
upper_bound <- Q3 + 1.5 * IQR_value

# Filter data to exclude outliers
filtered_data <- data %>%
  filter(unan_vce_Mean >= lower_bound & unan_vce_Mean <= upper_bound)

# Plot without outliers
ggplot(filtered_data, aes(x = as.factor(churn), y = unan_vce_Mean, fill = as.factor(churn))) +
  geom_boxplot() +
  theme_minimal() +
  scale_y_continuous(breaks = seq(floor(min(filtered_data$unan_vce_Mean)),
                                  ceiling(max(filtered_data$unan_vce_Mean)),
                                  by = 10)) +
  labs(title = "Caja de bigotes de Promedio de llamadas no contestadas por Churn",
       x = "Churn (0 = No, 1 = Sí)",
       y = "Llamadas no contestadas",
       fill = "Churn") +
  scale_fill_brewer(palette = "Set2")

```


La observación de que ambas cajas de bigotes (box plots) para los estados de churn (0 y 1) presentan un sesgo positivo y una mediana similar, con la mayoría de los datos en el rango de 5 a 30, sugiere que el promedio de llamadas no contestadas podría no ser un factor relevante para explicar el abandono del servicio. Si no se aprecian diferencias significativas en la distribución entre los clientes que permanecen (churn = 0) y los que abandonan (churn = 1), es probable que el promedio de llamadas no contestadas tenga una baja influencia en la decisión de abandono.

### **8.7 Caja de bigotes de Promedio de llamadas esperadas por Churn**

```{r}
# Calculate the IQR and define the outlier bounds
Q1 <- quantile(data$callwait_Mean, 0.25, na.rm = TRUE)
Q3 <- quantile(data$callwait_Mean, 0.75, na.rm = TRUE)
IQR_value <- Q3 - Q1

# Define the lower and upper bounds for outliers
lower_bound <- Q1 - 1.5 * IQR_value
upper_bound <- Q3 + 1.5 * IQR_value

# Filter data to exclude outliers
filtered_data <- data %>%
  filter(unan_vce_Mean >= lower_bound & callwait_Mean <= upper_bound)

# Plot without outliers
ggplot(filtered_data, aes(x = as.factor(churn), y = callwait_Mean, fill = as.factor(churn))) +
  geom_boxplot() +
  theme_minimal() +
  scale_y_continuous(breaks = seq(floor(min(filtered_data$callwait_Mean)),
                                  ceiling(max(filtered_data$callwait_Mean)),
                                  by = 0.1)) +
  labs(title = "Caja de bigotes de Promedio de llamadas esperadas por Churn",
       x = "Churn (0 = No, 1 = Sí)",
       y = "Promedio de llamadas esperadas",
       fill = "Churn") +
  scale_fill_brewer(palette = "Set2")
```


La observación de que ambas cajas de bigotes para los estados de churn (0 y 1) muestran un sesgo positivo, con medianas similares y la mayoría de los datos en el rango de 0.0 a 0.7 en el promedio de llamadas esperadas, sugiere que esta variable no es un factor diferenciador entre clientes que abandonan y aquellos que permanecen. La falta de diferencias significativas entre las distribuciones para churn indica que el promedio de llamadas esperadas probablemente no influye en la decisión de abandono.


### **8.8 Número total de meses en el servicio por Churn**


```{r}
# Calculate the IQR and define the outlier bounds
Q1 <- quantile(data$months, 0.25, na.rm = TRUE)
Q3 <- quantile(data$months, 0.75, na.rm = TRUE)
IQR_value <- Q3 - Q1

# Define the lower and upper bounds for outliers
lower_bound <- Q1 - 1.5 * IQR_value
upper_bound <- Q3 + 1.5 * IQR_value

# Filter data to exclude outliers
filtered_data <- data %>%
  filter(months >= lower_bound & months <= upper_bound)

# Plot without outliers
ggplot(filtered_data, aes(x = as.factor(churn), y = months, fill = as.factor(churn))) +
  geom_boxplot() +
  theme_minimal() +
  scale_y_continuous(breaks = seq(floor(min(filtered_data$months)),
                                  ceiling(max(filtered_data$months)),
                                  by = 10)) +
  labs(title = "Número total de meses en el servicio por Churn",
       x = "Churn (0 = No, 1 = Sí)",
       y = "Número total de meses en el servicio",
       fill = "Churn") +
  scale_fill_brewer(palette = "Set2")
```


Visualmente, no se observa una diferencia significativa en la influencia del número total de meses en el servicio sobre el churn. Esto se debe a que tanto la media de los datos como el tamaño de las cajas entre las categorías 0 y 1 son muy similares.


### **8.9 Edad del equipo por Churn**

```{r}
# Calculate the IQR and define the outlier bounds
Q1 <- quantile(data$eqpdays, 0.25, na.rm = TRUE)
Q3 <- quantile(data$eqpdays, 0.75, na.rm = TRUE)
IQR_value <- Q3 - Q1

# Define the lower and upper bounds for outliers
lower_bound <- Q1 - 1.5 * IQR_value
upper_bound <- Q3 + 1.5 * IQR_value

# Filter data to exclude outliers
filtered_data <- data %>%
  filter(eqpdays >= lower_bound & eqpdays <= upper_bound)

# Plot without outliers
ggplot(filtered_data, aes(x = as.factor(churn), y = eqpdays, fill = as.factor(churn))) +
  geom_boxplot() +
  theme_minimal() +
  scale_y_continuous(breaks = seq(floor(min(filtered_data$eqpdays)),
                                  ceiling(max(filtered_data$eqpdays)),
                                  by = 100)) +
  labs(title = "Edad del equipo por Churn",
       x = "Churn (0 = No, 1 = Sí)",
       y = "Edad del equipo",
       fill = "Churn") +
  scale_fill_brewer(palette = "Set2")
```


El boxplot sugiere una ligera tendencia que indica que los clientes que realizaron churn tienden a tener una mayor antigüedad con el dispositivo que utilizan. 


### **8.10 Precio del telefono por Churn**

```{r}
# Calculate the IQR and define the outlier bounds
Q1 <- quantile(data$hnd_price, 0.25, na.rm = TRUE)
Q3 <- quantile(data$hnd_price, 0.75, na.rm = TRUE)
IQR_value <- Q3 - Q1

# Define the lower and upper bounds for outliers
lower_bound <- Q1 - 1.5 * IQR_value
upper_bound <- Q3 + 1.5 * IQR_value

# Filter data to exclude outliers
filtered_data <- data %>%
  filter(hnd_price >= lower_bound & hnd_price <= upper_bound)

# Plot without outliers
ggplot(filtered_data, aes(x = as.factor(churn), y = hnd_price, fill = as.factor(churn))) +
  geom_boxplot() +
  theme_minimal() +
  scale_y_continuous(breaks = seq(floor(min(filtered_data$hnd_price)),
                                  ceiling(max(filtered_data$hnd_price)),
                                  by = 100)) +
  labs(title = "Precio del telefono por Churn",
       x = "Churn (0 = No, 1 = Sí)",
       y = "Precio del telefono",
       fill = "Churn") +
  scale_fill_brewer(palette = "Set2")
```


La gráfica sugiere que el precio del teléfono podría influir en la decisión de churn de un cliente. Sin embargo, sería necesario analizar esta relación en conjunto con otras variables para confirmar esta hipótesis. 


### **8.11 Minutos de uso mensual promedio por Churn**

```{r}
# Calculate the IQR and define the outlier bounds
Q1 <- quantile(data$mou_Mean, 0.25, na.rm = TRUE)
Q3 <- quantile(data$mou_Mean, 0.75, na.rm = TRUE)
IQR_value <- Q3 - Q1

# Define the lower and upper bounds for outliers
lower_bound <- Q1 - 1.5 * IQR_value
upper_bound <- Q3 + 1.5 * IQR_value

# Filter data to exclude outliers
filtered_data <- data %>%
  filter(mou_Mean >= lower_bound & mou_Mean <= upper_bound)

# Plot without outliers
ggplot(filtered_data, aes(x = as.factor(churn), y = mou_Mean, fill = as.factor(churn))) +
  geom_boxplot() +
  theme_minimal() +
  scale_y_continuous(breaks = seq(floor(min(filtered_data$mou_Mean)),
                                  ceiling(max(filtered_data$mou_Mean)),
                                  by = 100)) +
  labs(title = "Minutos de uso mensual promedio por Churn",
       x = "Churn (0 = No, 1 = Sí)",
       y = "Minutos de uso mensual promedio",
       fill = "Churn") +
  scale_fill_brewer(palette = "Set2")
```


La gráfica no permite determinar si el promedio de minutos de uso mensual tiene alguna influencia en el churn de los clientes. 


### **8.12 Cargo recurrente mensual total promedio por Churn.**

```{r}
# Calculate the IQR and define the outlier bounds
Q1 <- quantile(data$totmrc_Mean, 0.25, na.rm = TRUE)
Q3 <- quantile(data$totmrc_Mean, 0.75, na.rm = TRUE)
IQR_value <- Q3 - Q1

# Define the lower and upper bounds for outliers
lower_bound <- Q1 - 1.5 * IQR_value
upper_bound <- Q3 + 1.5 * IQR_value

# Filter data to exclude outliers
filtered_data <- data %>%
  filter(totmrc_Mean >= lower_bound & totmrc_Mean <= upper_bound)

# Plot without outliers
ggplot(filtered_data, aes(x = as.factor(churn), y = totmrc_Mean, fill = as.factor(churn))) +
  geom_boxplot() +
  theme_minimal() +
  scale_y_continuous(breaks = seq(floor(min(filtered_data$totmrc_Mean)),
                                  ceiling(max(filtered_data$totmrc_Mean)),
                                  by = 10)) +
  labs(title = "Cargo recurrente mensual total promedio por Churn",
       x = "Churn (0 = No, 1 = Sí)",
       y = "Cargo recurrente mensual total promedio",
       fill = "Churn") +
  scale_fill_brewer(palette = "Set2")
```

Se observa una ligera relación entre los clientes que no realizaron churn y el promedio del cargo recurrente mensual total. 


### **8.13 Número de telefonos por Churn**

```{r}
# Calculate the IQR and define the outlier bounds
Q1 <- quantile(data$phones, 0.25, na.rm = TRUE)
Q3 <- quantile(data$phones, 0.75, na.rm = TRUE)
IQR_value <- Q3 - Q1

# Define the lower and upper bounds for outliers
lower_bound <- Q1 - 1.5 * IQR_value
upper_bound <- Q3 + 1.5 * IQR_value

# Filter data to exclude outliers
filtered_data <- data %>%
  filter(phones >= lower_bound & phones <= upper_bound)

# Plot without outliers
ggplot(filtered_data, aes(x = as.factor(churn), y = phones, fill = as.factor(churn))) +
  geom_boxplot() +
  theme_minimal() +
  scale_y_continuous(breaks = seq(floor(min(filtered_data$phones)),
                                  ceiling(max(filtered_data$phones)),
                                  by = 1)) +
  labs(title = "Número de telefonos por Churn",
       x = "Churn (0 = No, 1 = Sí)",
       y = "Número de telefonos",
       fill = "Churn") +
  scale_fill_brewer(palette = "Set2")
```


Visualmente, no es posible distinguir si existe una relación entre el número de teléfonos y la decisión del cliente de hacer churn. 


## **9. Análisis Multivariado**
```{r}
data_numerico <- select_if(data, is.numeric)
```

```{r}
data_subset <- data[, c("drop_vce_Mean", "drop_dat_Mean", "blck_vce_Mean",
                        "blck_dat_Mean", "unan_vce_Mean", "unan_dat_Mean",
                        "plcd_vce_Mean", "plcd_dat_Mean")]
```

```{r}
# Calcular la matriz de correlación para las variables seleccionadas
cor_matrix <- cor(data_subset, use = "complete.obs", method = "pearson")

# Visualizar la matriz de correlación
corrplot(cor_matrix, method = "color", tl.col = "black", tl.cex = 0.8)
```

Teniendo en cuenta que analizamos un conjunto de variables continúas relacionadas con el número promedio de llamadas no exitosas, y basándonos en el mapa de calor de la correlación de Pearson, concluimos que dichas variables presentan una correlación positiva (mayor o igual a cero). Sin embargo, esta correlación no es lo suficientemente fuerte como para considerarse significativa. Aunque la correlación no sea fuerte, es importante explorar si hay un cambio en el comportamiento del cliente en función de otras características o situaciones.


```{r}
data_subset1 <- data[, c("recv_vce_Mean","recv_sms_Mean","comp_vce_Mean","comp_dat_Mean")]
```

```{r}
cor_matrix1 <- cor(data_subset1, use = "complete.obs", method = "pearson")

corrplot(cor_matrix1, method = "color", tl.col = "black", tl.cex = 0.8)
```

La conclusión de que las variables relacionadas con el número promedio de llamadas exitosas muestran una correlación positiva, pero no lo suficientemente fuerte como para considerarse significativa, ofrece varias implicaciones para el análisis de los factores que afectan el churn y el comportamiento de los clientes. Al igual que en el caso de las llamadas no exitosas, esta correlación débil sugiere que, aunque hay una relación positiva, esta no es lo suficientemente fuerte como para ser un factor determinante en la predicción del abandono o la lealtad del cliente.


```{r}
data_subset3 <- data[, c("totcalls","totmou")]
```

```{r}
cor_matrix2 <- cor(data_subset3, use = "complete.obs", method = "pearson")

corrplot(cor_matrix2, method = "color", tl.col = "black", tl.cex = 0.8)
```

La relacion entre las variables Número total de llamadas a lo largo de la vida del cliente y Total de minutos de uso a lo largo de la vida del cliente estan muy correlacionadas.

```{r}
variables_numericas <- data %>%
  select_if(is.numeric)
print(variables_numericas)
```


```{r}
# Calcular la matriz de correlaciones
correlaciones <- cor(variables_numericas, data$churn)
print(correlaciones)
```
```{r}
# Ordenar las correlaciones de mayor a menor en valor absoluto (mirar si corre sin la funcion abs) para poder ver cuales son las variables con esas altas correlaciones
correlaciones <- sort(abs(correlaciones), decreasing = TRUE)

# Mostrar las 10 variables con mayor correlación absoluta
head(correlaciones, 10)
```
```{r}
# Seleccionar únicamente las columnas numéricas
variables_numericas <- data %>%
  select_if(is.numeric)
print(variables_numericas)
```

```{r}
# Calcular la matriz de correlaciones
correlaciones <- cor(variables_numericas, data$churn)
print(correlaciones)
```
```{r}
# Prueba t de Student
resultado_ttest <- t.test(income ~ churn, data = data)

print(resultado_ttest)
```

Dado que churn es una variable binaria, la prueba t de muestras independientes es la opción adecuada para comparar los promedios de income entre los dos grupos. Los resultados indican lo siguiente:

Estadístico t = -1.781: Esto significa que hay una diferencia en los ingresos medios entre los dos grupos, aunque no es muy grande. Un valor t negativo indica que el promedio de ingresos para los usuarios que no hicieron churn (churn = 0) es mayor que el de los que hicieron churn (churn = 1).

Grados de libertad (df = 99998): Al ser una muestra muy grande, el número de grados de libertad es casi igual al tamaño de la muestra menos 2. Esto generalmente da más poder a la prueba estadística.

p-value = 0.07491: Este valor es cercano al nivel de significancia típico (α = 0.05), pero no lo alcanza. Esto sugiere que, al usar un nivel de significancia del 5%, la diferencia en los promedios de income entre los dos grupos no es estadísticamente significativa.

En resumen, aunque parece haber una diferencia en los ingresos entre los dos grupos, la prueba t indica que no es lo suficientemente fuerte como para ser estadísticamente significativa al 5%. Sin embargo, al 10%, la diferencia podría ser considerada significativa.

```{r}
# Prueba t de Student
data$adults <- as.numeric(as.character(data$adults))

resultado_ttest1 <- t.test(adults ~ churn, data = data)

print(resultado_ttest1)
```

Al analizar churn con el numero de adultos en el hogar tenemos los siguientes resultados: t = 3.4645, df = 99996, p-value = 0.0005314
Este resultado sugiere que el número de adultos en el hogar tiene una influencia significativa en el churn, con los hogares con más adultos mostrando una mayor tendencia a hacer churn. Esto podría implicar que la composición del hogar es un factor relevante para entender el comportamiento de abandono.

```{r}
# Prueba t de Student
resultado_ttest2 <- t.test(totcalls ~ churn, data = data)

print(resultado_ttest2)
```

Al analizar churn con el Número total de llamadas a lo largo de la vida del cliente tenemos los siguientes resultados: t = 4.9978, df = 97884, p-value = 5.808e-07
El resultado sugiere que los clientes que tienden a hacer churn realizaron, en promedio, más llamadas durante su tiempo como clientes. Este hallazgo podría indicar que los usuarios con mayor actividad telefónica tienen más probabilidades de abandonar el servicio, o que el aumento en el número de llamadas podría estar relacionado con algún tipo de insatisfacción o comportamiento que precede al churn.

```{r}
# Prueba t de Student
resultado_ttest3 <- t.test(months ~ churn, data = data)

print(resultado_ttest3)
```

Al analizar churn con el Número total de meses de servicio tenemos los siguientes resultados: t = -6.6433, df = 99739, p-value = 3.083e-11.
Este resultado indica que los clientes que hicieron churn (churn = 1) tuvieron un menor número total de meses de servicio en comparación con aquellos que no hicieron churn. La diferencia es estadísticamente significativa, lo que sugiere que la duración del servicio es un factor relevante para predecir el churn. Los clientes que permanecen menos tiempo en el servicio son más propensos a abandonar.

```{r}
# Prueba t de Student
resultado_ttest4 <- t.test(custcare_Mean ~ churn, data = data)

print(resultado_ttest4)
```

Al analizar churn con el Número medio de llamadas al servicio de atención al cliente tenemos los siguientes resultados: t = 11.522, df = 99824, p-value < 2.2e-16.
Este resultado sugiere que los clientes que hicieron churn (churn = 1) realizaron un número significativamente mayor de llamadas al servicio de atención al cliente en comparación con los clientes que no hicieron churn (churn = 0). La diferencia es estadísticamente significativa, lo que puede indicar que los clientes que se sienten insatisfechos o tienen problemas frecuentes tienden a llamar más al servicio de atención y tienen una mayor probabilidad de abandonar el servicio.

## **10. Modelamiento**
### **10.1 Selecionar las colmunas para entrenar el modelo**

```{r}
# Selecting specific columns
selected_columns <- data %>%
  select(phones, totmrc_Mean, mou_Mean, hnd_price, eqpdays, months, 
         adults, ethnic, totcalls, totmou, drop_vce_Mean, new_cell, churn)
head(selected_columns)
```

### **10.2 Convertir datos categóricos en variables numéricas**

```{r}
# Define target and predictor variables
target <- selected_columns$churn
predictors <- selected_columns %>%
  select(-churn)  # Exclude target variable from predictors

# Ensure that categorical variables like 'ethnic' are factors
predictors$ethnic <- as.factor(predictors$ethnic)

# Perform label encoding for the 'ethnic' variable (convert factor to integer)
predictors$ethnic <- as.numeric(predictors$ethnic)

# One-hot encode other categorical variables, if needed (optional)
dummy_vars <- dummyVars(" ~ .", data = predictors)
encoded_data <- predict(dummy_vars, newdata = predictors) %>%
  as.data.frame() %>%
  mutate(churn = target)  # Add target variable back

# View the final dataset
head(encoded_data)


```

### **10.3 Guardar los datos para usarlos como conjunto de entrenamiento**

```{r}
# Assuming 'encoded_data' is the dataset with the encoded categorical variables
target <- encoded_data$churn  # target variable (churn)
predictors <- encoded_data %>%
  select(-churn)  # remove the target variable from the predictors

# Convert predictors and target into matrix format
train_x <- as.matrix(predictors)
train_y <- as.numeric(target)  # Convert target to numeric (0 or 1)
```

### **10.4  Probar distintos modelos de clasificación**

```{r message=FALSE, warning=FALSE, echo=TRUE, results='hide'}
# Set a seed for reproducibility
set.seed(123)

# Calculate the sample size (1% of the original data)
sample_size <- floor(0.10 * nrow(train_x))  # 1% of the number of rows

# Sample the rows from both train_x and train_y
sample_indices <- sample(nrow(train_x), size = sample_size)

# Subset the data
train_x_sampled <- train_x[sample_indices, ]
train_y_sampled <- train_y[sample_indices]

# Optionally, if you want to convert train_y to numeric (if not done already)
train_y_sampled <- as.numeric(train_y_sampled)  # Ensures it's numeric (0 or 1)



# Ensure valid class levels for R variable names
train_y_sampled <- factor(train_y_sampled)
levels(train_y_sampled) <- make.names(levels(train_y_sampled))  # Make class names valid

# Define Training Control with class probabilities enabled
train_control <- trainControl(
  method = "cv",           # Cross-validation
  number = 10,              # Number of folds
  savePredictions = "final",
  classProbs = TRUE,       # Request class probabilities for ROC
  summaryFunction = twoClassSummary  # Use ROC, Sensitivity, Specificity for binary classification
)

# Define Models to Compare
model_list <- c("glm", "rf", "gbm", "svmRadial", "nnet", "xgbTree")

# Train Each Model Using Matrix Input
model_results <- list()
for (model in model_list) {
  set.seed(123)  # Ensure reproducibility
  
  # Model-specific adjustments for class probabilities
  if (model == "xgbTree") {
    # Ensure binary classification with probabilities
    model_results[[model]] <- train(
      x = train_x_sampled,
      y = train_y_sampled,
      method = model,
      trControl = train_control,
      metric = "ROC",
      tuneLength = 5,
      objective = "binary:logistic"  # Ensure binary classification with class probabilities
    )
  } else if (model == "nnet") {
    # Set linout = FALSE for nnet to output probabilities
    model_results[[model]] <- train(
      x = train_x_sampled,
      y = train_y_sampled,
      method = model,
      trControl = train_control,
      metric = "ROC",
      linout = FALSE  # Ensures class probabilities are output
    )
  } else {
    model_results[[model]] <- train(
      x = train_x_sampled,
      y = train_y_sampled,
      method = model,
      trControl = train_control,
      metric = "ROC"
    )
  }
}

# Summarize Results
resamples_results <- resamples(model_results)
summary(resamples_results)

# Visualize Results
bwplot(resamples_results, metric = "ROC")

# Best Model Based on ROC
best_model_name <- names(which.max(sapply(model_results, function(x) max(x$results$ROC))))
best_model <- model_results[[best_model_name]]
cat("Best Model: ", best_model_name, "\n")
print(best_model)
```


La gráfica compara el desempeño de diferentes modelos de machine learning en términos del área bajo la curva ROC, destacando que **gbm**, **xgbTree** y **rf** son los más efectivos, siendo **gbm** el mejor, seguido de cerca por **xgbTree**, mientras que **rf** presenta un rendimiento ligeramente menor.


### **10.5 Configuración de los parámetros para la optimización de los modelos XGBoost, GBM, y RF**


```{r}
# Hyperparameters for XGBoost (as provided)
tune_grid_xgb <- expand.grid(
  nrounds = c(50, 100, 150),
  max_depth = c(3, 6, 10),
  eta = c(0.01, 0.1, 0.3),
  gamma = c(0, 1),
  colsample_bytree = c(0.6, 0.8),
  min_child_weight = c(1, 5),
  subsample = c(0.6, 0.8)
)

# Hyperparameters for GBM
tune_grid_gbm <- expand.grid(
  n.trees = c(50, 100, 150),
  interaction.depth = c(3, 5, 7),
  shrinkage = c(0.01, 0.1, 0.3),
  n.minobsinnode = c(5, 10)
)

# Hyperparameters for Random Forest (RF)
tune_grid_rf <- expand.grid(
  mtry = c(2, 4, 6, 8)  # Number of variables to sample at each split
)
```


### **10.6 Configurar el control de validación cruzada.**

```{r}
# Set up cross-validation control
train_control <- trainControl(
  method = "cv",         # Cross-validation
  number = 10,            # 5-fold cross-validation
  verboseIter = TRUE     # Show progress of the tuning process
)
```


### **10.7 Tuning de XGBoost**

```{r warning=FALSE, include=FALSE}
set.seed(123)
subset_data <- encoded_data[sample(1:nrow(encoded_data), size = 0.1 * nrow(encoded_data)), ]
xgb_tune <- train(
  churn ~ .,                # Formula: predict churn based on all other variables
  data = subset_data,       # Use subset data
  method = "xgbTree",       # XGBoost model
  trControl = train_control, # Cross-validation setup
  tuneGrid = tune_grid_xgb   # Hyperparameter grid for XGBoost
)
```

```{r}
# Print best XGBoost hyperparameters
print(xgb_tune$bestTune)
```


### **10.8 Entrenar el modelo XGBoost con los mejores hiperparámetros**


```{r warning=FALSE}
# Convert the dataset into an XGBoost-compatible format
dtrain <- xgb.DMatrix(data = train_x, label = train_y)

# Set parameters for binary classification
params_xgb <- list(
  objective = "binary:logistic",
  eval_metric = "error",
  max_depth = xgb_tune$bestTune$max_depth,
  eta = xgb_tune$bestTune$eta,
  nthread = 3,
  gamma = xgb_tune$bestTune$gamma,
  subsample = xgb_tune$bestTune$subsample,
  colsample_bytree = xgb_tune$bestTune$colsample_bytree
)
```



```{r warning=FALSE}
# Train the model
model_xgb <- xgb.train(params_xgb, dtrain, nrounds = xgb_tune$bestTune$nrounds)
```

### **10.9 Tuning de GBM**

```{r}
# Perform tuning for GBM using the subset data
gbm_tune <- train(
  churn ~ .,                # Formula: predict churn based on all other variables
  data = subset_data,       # Use subset data
  method = "gbm",           # Generalized Boosting Model
  trControl = train_control, # Cross-validation setup
  tuneGrid = tune_grid_gbm   # Hyperparameter grid for GBM
)

# Print best GBM hyperparameters
print(gbm_tune$bestTune)
```


### **10.10 Entrenar el modelo GBM con los mejores hiperparámetros**


```{r}
# Train the model using the best hyperparameters
library(gbm)

model_gbm <- gbm(
  churn ~ ., 
  data = subset_data, 
  distribution = "bernoulli", 
  n.trees = gbm_tune$bestTune$n.trees,
  interaction.depth = gbm_tune$bestTune$interaction.depth,
  shrinkage = gbm_tune$bestTune$shrinkage,
  n.minobsinnode = gbm_tune$bestTune$n.minobsinnode
)
```


### **10.11 Tuning de Random Forest (RF)**

```{r warning=FALSE, include=FALSE}
# Ensure that 'churn' is a factor for classification
subset_data$churn <- as.factor(subset_data$churn)

# Perform tuning for Random Forest using the subset data
rf_tune <- train(
  churn ~ .,                # Formula: predict churn based on all other variables
  data = subset_data,       # Use subset data
  method = "rf",            # Random Forest model
  trControl = train_control, # Cross-validation setup
  tuneGrid = tune_grid_rf    # Hyperparameter grid for Random Forest
)

```


```{r}
# Print best Random Forest hyperparameters
print(rf_tune$bestTune)
```


### **10.12 Entrenar el modelo RF con los mejores hiperparámetros**

```{r warning=FALSE}
library(randomForest)
# Train the model using the best hyperparameters
model_rf <- randomForest(
  churn ~ ., 
  data = subset_data,
  mtry = rf_tune$bestTune$mtry,
  nodesize = rf_tune$bestTune$min.node.size
)
```



### **10.13 Evaluación de los modelos**
```{r}
# Convert train_x to a numeric matrix
train_x <- as.matrix(train_x)

# Ensure train_y is numeric for xgboost
train_y <- as.numeric(as.character(train_y))

```


```{r}
# Evaluate XGBoost performance
predictions_xgb <- predict(model_xgb, train_x)
predictions_xgb_binary <- ifelse(predictions_xgb > 0.5, 1, 0)
confusionMatrix(factor(predictions_xgb_binary), factor(train_y))
```

```{r}
train_x <- as.data.frame(train_x)

# Evaluate GBM performance
predictions_gbm <- predict(model_gbm, train_x, n.trees = gbm_tune$bestTune$n.trees)
predictions_gbm_binary <- ifelse(predictions_gbm > 0.5, 1, 0)  # Convert probabilities to binary
confusionMatrix(factor(predictions_gbm_binary), factor(train_y))
```


```{r}
# Evaluate Random Forest performance
predictions_rf <- predict(model_rf, train_x)
confusionMatrix(factor(predictions_rf), factor(train_y))
```

Se observa que el **accuracy** del modelo **XGBoost** es de **0.616**, el de **GBM** es de **0.5653** y el de **Random Forest** es de **0.6377**. Esto indica que el modelo con mejor desempeño, en términos de exactitud, es **Random Forest**, por lo que sería el más adecuado para su implementación.